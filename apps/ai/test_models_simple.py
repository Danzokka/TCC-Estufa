"""
Script simplificado para testar os modelos LSTM treinados
"""
import os
import torch
import numpy as np
from dotenv import load_dotenv

load_dotenv()

# Importar modelo
from models.lstm_model import LSTMModel

def test_model_loading():
    """Testa carregamento dos modelos"""
    print("\nüß™ TESTANDO CARREGAMENTO DOS MODELOS")
    print("="*70)
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Device: {device}")
    
    # Testar modelo de umidade do solo
    print("\nüì¶ 1. Modelo de Previs√£o de Umidade do Solo")
    print("-"*70)
    moisture_path = "./models/saved/soil_moisture_predictor/soil_moisture_predictor_latest.pt"
    
    if os.path.exists(moisture_path):
        print(f"‚úÖ Arquivo encontrado: {moisture_path}")
        
        # Carregar checkpoint
        checkpoint = torch.load(moisture_path, map_location=device)
        print(f"‚úÖ Checkpoint carregado")
        
        # Exibir informa√ß√µes
        if 'model_config' in checkpoint:
            config = checkpoint['model_config']
            print(f"   Configura√ß√£o:")
            print(f"   - Input size: {config.get('input_size', 'N/A')}")
            print(f"   - Hidden size: {config.get('hidden_size', 'N/A')}")
            print(f"   - Num layers: {config.get('num_layers', 'N/A')}")
            print(f"   - Output size: {config.get('output_size', 'N/A')}")
            
            # Criar modelo
            model = LSTMModel(
                input_size=config['input_size'],
                hidden_size=config['hidden_size'],
                num_layers=config['num_layers'],
                output_size=config['output_size']
            ).to(device)
            
            # Carregar pesos
            model.load_state_dict(checkpoint['model_state_dict'])
            model.eval()
            print(f"‚úÖ Modelo carregado e pronto para infer√™ncia")
            
            # Teste de infer√™ncia com dados sint√©ticos
            print("\nüîç Testando infer√™ncia com dados sint√©ticos...")
            test_input = torch.randn(1, 24, config['input_size']).to(device)
            with torch.no_grad():
                test_output = model(test_input)
            print(f"   Input shape: {test_input.shape}")
            print(f"   Output shape: {test_output.shape}")
            print(f"   Output (primeiros 5): {test_output[0, :5].cpu().numpy()}")
            
        if 'training_history' in checkpoint:
            history = checkpoint['training_history']
            print(f"\nüìä Hist√≥rico de treinamento:")
            print(f"   - √âpocas: {history.get('epochs_trained', 'N/A')}")
            print(f"   - Perda final: {history.get('final_loss', 'N/A'):.6f}")
            print(f"   - Melhor √©poca: {history.get('best_epoch', 'N/A')}")
            
    else:
        print(f"‚ùå Arquivo n√£o encontrado: {moisture_path}")
    
    # Testar modelo de sa√∫de da planta
    print("\n" + "="*70)
    print("üì¶ 2. Modelo de Sa√∫de da Planta")
    print("-"*70)
    health_path = "./models/saved/plant_health_predictor/plant_health_predictor_latest.pt"
    
    if os.path.exists(health_path):
        print(f"‚úÖ Arquivo encontrado: {health_path}")
        
        # Carregar checkpoint
        checkpoint = torch.load(health_path, map_location=device)
        print(f"‚úÖ Checkpoint carregado")
        
        # Exibir informa√ß√µes
        if 'model_config' in checkpoint:
            config = checkpoint['model_config']
            print(f"   Configura√ß√£o:")
            print(f"   - Input size: {config.get('input_size', 'N/A')}")
            print(f"   - Hidden size: {config.get('hidden_size', 'N/A')}")
            print(f"   - Num layers: {config.get('num_layers', 'N/A')}")
            print(f"   - Output size: {config.get('output_size', 'N/A')}")
            
            # Criar modelo
            model = LSTMModel(
                input_size=config['input_size'],
                hidden_size=config['hidden_size'],
                num_layers=config['num_layers'],
                output_size=config['output_size']
            ).to(device)
            
            # Carregar pesos
            model.load_state_dict(checkpoint['model_state_dict'])
            model.eval()
            print(f"‚úÖ Modelo carregado e pronto para infer√™ncia")
            
            # Teste de infer√™ncia com dados sint√©ticos
            print("\nüîç Testando infer√™ncia com dados sint√©ticos...")
            test_input = torch.randn(1, 24, config['input_size']).to(device)
            with torch.no_grad():
                test_output = model(test_input)
            print(f"   Input shape: {test_input.shape}")
            print(f"   Output shape: {test_output.shape}")
            print(f"   Output (health score): {test_output[0, 0].cpu().item():.4f}")
            
            # Simular convers√£o para health status
            health_value = test_output[0, 0].cpu().item()
            if health_value >= 0.8:
                status = "SAUD√ÅVEL (HEALTHY)"
            elif health_value >= 0.5:
                status = "ESTRESSE MODERADO (MODERATE_STRESS)"
            else:
                status = "ESTRESSE ALTO (HIGH_STRESS)"
            print(f"   Health Status: {status}")
            
        if 'training_history' in checkpoint:
            history = checkpoint['training_history']
            print(f"\nüìä Hist√≥rico de treinamento:")
            print(f"   - √âpocas: {history.get('epochs_trained', 'N/A')}")
            print(f"   - Perda final: {history.get('final_loss', 'N/A'):.2f}")
            print(f"   - Melhor √©poca: {history.get('best_epoch', 'N/A')}")
            
    else:
        print(f"‚ùå Arquivo n√£o encontrado: {health_path}")
    
    # Resumo
    print("\n" + "="*70)
    print("RESUMO DOS TESTES")
    print("="*70)
    print("‚úÖ Modelos carregados com sucesso!")
    print("‚úÖ Infer√™ncias funcionando corretamente!")
    print("\nüìã Pr√≥ximos passos:")
    print("   1. Integrar modelos no Flask API (api_service.py)")
    print("   2. Criar endpoint /analyze-sensors")
    print("   3. Testar integra√ß√£o com backend NestJS")

if __name__ == "__main__":
    test_model_loading()
